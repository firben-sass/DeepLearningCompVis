{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBzUg31heLk9"
      },
      "source": [
        "## Exercise 1.4 Hotdog -- no hotdog\n",
        "This is the poster hand-in project for the course. Please see the associated PDF for instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WULumtifpB1U",
        "outputId": "34875083-acbe-4747-d764-cb155396ee0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DRIhx7PugJy3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import PIL.Image as Image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "from torchinfo import summary\n",
        "\n",
        "from typing import Dict, List, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35PhqXpWUZ7I"
      },
      "source": [
        "We always check that we are running on a GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic_gOv_pUZeB",
        "outputId": "9becf3b6-944f-4d24-d6bb-ed9f3b16235c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"The code will run on GPU.\")\n",
        "else:\n",
        "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4mUlnOuzgJzF"
      },
      "outputs": [],
      "source": [
        "class Hotdog_NotHotdog(torch.utils.data.Dataset):\n",
        "    def __init__(self, train, transform, data_path='/content/hotdog_nothotdog'):\n",
        "        'Initialization'\n",
        "        self.transform = transform\n",
        "        data_path = os.path.join(data_path, 'train' if train else 'test')\n",
        "        image_classes = [os.path.split(d)[1] for d in glob.glob(data_path +'/*') if os.path.isdir(d)]\n",
        "        image_classes.sort()\n",
        "        self.name_to_label = {c: id for id, c in enumerate(image_classes)}\n",
        "        self.image_paths = glob.glob(data_path + '/*/*.jpg')\n",
        "\n",
        "    def __len__(self):\n",
        "        'Returns the total number of samples'\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        'Generates one sample of data'\n",
        "        image_path = self.image_paths[idx]\n",
        "\n",
        "        image = Image.open(image_path)\n",
        "        c = os.path.split(os.path.split(image_path)[0])[1]\n",
        "        y = self.name_to_label[c]\n",
        "        X = self.transform(image)\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m3-DGqEgHOw"
      },
      "source": [
        "## Transfer Learning: EfficientNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5hmJcvlqNU5"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GDLCvw0Qs3MM"
      },
      "outputs": [],
      "source": [
        "# Define helper functions\n",
        "def plot_pictures(loader: DataLoader, quantity: int):\n",
        "  images, labels = next(iter(loader))\n",
        "  plt.figure(figsize=(20,10))\n",
        "\n",
        "  for i in range(quantity):\n",
        "      plt.subplot(5,7,i+1)\n",
        "      plt.imshow(np.swapaxes(np.swapaxes(images[i].numpy(), 0, 2), 0, 1))\n",
        "      plt.title(['hotdog', 'not hotdog'][labels[i].item()])\n",
        "      plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JewkmhKlgJzN"
      },
      "source": [
        "Perform data transform to dataset as in EfficientNetV1 model:\n",
        "- Resize (128, 128)\n",
        "- To Tensor (0,1)\n",
        "- Mean and std normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcilkL3dgJzP",
        "outputId": "052b39b0-4fd7-49de-ad81-380e9897c109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of cores available: 2\n",
            "Size of train dataset: 2047, size of test dataset: 30\n"
          ]
        }
      ],
      "source": [
        "# Define paramenter for tranformer\n",
        "size = 128\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Define transformer\n",
        "train_transformer = transforms.Compose([transforms.Resize((size, size)),\n",
        "                                        transforms.RandomRotation(10),\n",
        "                                        transforms.RandomHorizontalFlip(),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=mean,\n",
        "                                                             std=std)])\n",
        "test_transformer = transforms.Compose([transforms.Resize((size, size)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=mean,\n",
        "                                                            std=std)])\n",
        "# Create train and test dataloaders\n",
        "batch_size = 64\n",
        "num_workers = os.cpu_count()  # detects number of CPUs\n",
        "print(f'Number of cores available: {num_workers}')\n",
        "trainset = Hotdog_NotHotdog(train=True, transform=train_transformer)# Train\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=min(2, num_workers))\n",
        "testset = Hotdog_NotHotdog(train=False, transform=test_transformer)# Test\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=min(2, num_workers))\n",
        "# Verify data size\n",
        "print(f'Size of train dataset: {len(trainset)}, size of test dataset: {len(test_loader)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqAdZ4I2vC9e"
      },
      "source": [
        "### Set up pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OtKlIuuYvHl1"
      },
      "outputs": [],
      "source": [
        "# Set up weights\n",
        "weights = models.EfficientNet_B7_Weights.DEFAULT # .DEFAULT = best available weights for ImageNet\n",
        "model = models.efficientnet_b7(weights=weights).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhtXv6Jayhor"
      },
      "source": [
        "Efficientnet_b7 comes in three main parts:\n",
        "\n",
        "- features - A collection of convolutional layers and other various activation layers to learn a base representation of vision data (this base representation/collection of layers is often referred to as features or feature extractor, \"the base layers of the model learn the different features of images\").\n",
        "- avgpool - Takes the average of the output of the features layer(s) and turns it into a feature vector.\n",
        "- classifier - Turns the feature vector into a vector with the same dimensionality as the number of required output classes (since efficientnet_b0 is pretrained on ImageNet and because ImageNet has 1000 classes, out_features=1000 is the default)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir7_wewGvQpV",
        "outputId": "7e37d483-48ed-4a3b-d757-a0e65299b74c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "EfficientNet (EfficientNet)                                  [32, 3, 128, 128]    [32, 1000]           --                   True\n",
              "├─Sequential (features)                                      [32, 3, 128, 128]    [32, 2560, 4, 4]     --                   True\n",
              "│    └─Conv2dNormActivation (0)                              [32, 3, 128, 128]    [32, 64, 64, 64]     --                   True\n",
              "│    │    └─Conv2d (0)                                       [32, 3, 128, 128]    [32, 64, 64, 64]     1,728                True\n",
              "│    │    └─BatchNorm2d (1)                                  [32, 64, 64, 64]     [32, 64, 64, 64]     128                  True\n",
              "│    │    └─SiLU (2)                                         [32, 64, 64, 64]     [32, 64, 64, 64]     --                   --\n",
              "│    └─Sequential (1)                                        [32, 64, 64, 64]     [32, 32, 64, 64]     --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 64, 64, 64]     [32, 32, 64, 64]     4,944                True\n",
              "│    │    └─MBConv (1)                                       [32, 32, 64, 64]     [32, 32, 64, 64]     1,992                True\n",
              "│    │    └─MBConv (2)                                       [32, 32, 64, 64]     [32, 32, 64, 64]     1,992                True\n",
              "│    │    └─MBConv (3)                                       [32, 32, 64, 64]     [32, 32, 64, 64]     1,992                True\n",
              "│    └─Sequential (2)                                        [32, 32, 64, 64]     [32, 48, 32, 32]     --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 32, 64, 64]     [32, 48, 32, 32]     21,224               True\n",
              "│    │    └─MBConv (1)                                       [32, 48, 32, 32]     [32, 48, 32, 32]     38,700               True\n",
              "│    │    └─MBConv (2)                                       [32, 48, 32, 32]     [32, 48, 32, 32]     38,700               True\n",
              "│    │    └─MBConv (3)                                       [32, 48, 32, 32]     [32, 48, 32, 32]     38,700               True\n",
              "│    │    └─MBConv (4)                                       [32, 48, 32, 32]     [32, 48, 32, 32]     38,700               True\n",
              "│    │    └─MBConv (5)                                       [32, 48, 32, 32]     [32, 48, 32, 32]     38,700               True\n",
              "│    │    └─MBConv (6)                                       [32, 48, 32, 32]     [32, 48, 32, 32]     38,700               True\n",
              "│    └─Sequential (3)                                        [32, 48, 32, 32]     [32, 80, 16, 16]     --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 48, 32, 32]     [32, 80, 16, 16]     52,588               True\n",
              "│    │    └─MBConv (1)                                       [32, 80, 16, 16]     [32, 80, 16, 16]     110,580              True\n",
              "│    │    └─MBConv (2)                                       [32, 80, 16, 16]     [32, 80, 16, 16]     110,580              True\n",
              "│    │    └─MBConv (3)                                       [32, 80, 16, 16]     [32, 80, 16, 16]     110,580              True\n",
              "│    │    └─MBConv (4)                                       [32, 80, 16, 16]     [32, 80, 16, 16]     110,580              True\n",
              "│    │    └─MBConv (5)                                       [32, 80, 16, 16]     [32, 80, 16, 16]     110,580              True\n",
              "│    │    └─MBConv (6)                                       [32, 80, 16, 16]     [32, 80, 16, 16]     110,580              True\n",
              "│    └─Sequential (4)                                        [32, 80, 16, 16]     [32, 160, 8, 8]      --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 80, 16, 16]     [32, 160, 8, 8]      141,460              True\n",
              "│    │    └─MBConv (1)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      397,800              True\n",
              "│    │    └─MBConv (2)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      397,800              True\n",
              "│    │    └─MBConv (3)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      397,800              True\n",
              "│    │    └─MBConv (4)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      397,800              True\n",
              "│    │    └─MBConv (5)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      397,800              True\n",
              "│    │    └─MBConv (6)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      397,800              True\n",
              "│    │    └─MBConv (7)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      397,800              True\n",
              "│    │    └─MBConv (8)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      397,800              True\n",
              "│    │    └─MBConv (9)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      397,800              True\n",
              "│    └─Sequential (5)                                        [32, 160, 8, 8]      [32, 224, 8, 8]      --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 160, 8, 8]      [32, 224, 8, 8]      474,728              True\n",
              "│    │    └─MBConv (1)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      793,464              True\n",
              "│    │    └─MBConv (2)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      793,464              True\n",
              "│    │    └─MBConv (3)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      793,464              True\n",
              "│    │    └─MBConv (4)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      793,464              True\n",
              "│    │    └─MBConv (5)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      793,464              True\n",
              "│    │    └─MBConv (6)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      793,464              True\n",
              "│    │    └─MBConv (7)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      793,464              True\n",
              "│    │    └─MBConv (8)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      793,464              True\n",
              "│    │    └─MBConv (9)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      793,464              True\n",
              "│    └─Sequential (6)                                        [32, 224, 8, 8]      [32, 384, 4, 4]      --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 224, 8, 8]      [32, 384, 4, 4]      1,008,824            True\n",
              "│    │    └─MBConv (1)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      2,281,824            True\n",
              "│    │    └─MBConv (2)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      2,281,824            True\n",
              "│    │    └─MBConv (3)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      2,281,824            True\n",
              "│    │    └─MBConv (4)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      2,281,824            True\n",
              "│    │    └─MBConv (5)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      2,281,824            True\n",
              "│    │    └─MBConv (6)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      2,281,824            True\n",
              "│    │    └─MBConv (7)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      2,281,824            True\n",
              "│    │    └─MBConv (8)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      2,281,824            True\n",
              "│    │    └─MBConv (9)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      2,281,824            True\n",
              "│    │    └─MBConv (10)                                      [32, 384, 4, 4]      [32, 384, 4, 4]      2,281,824            True\n",
              "│    │    └─MBConv (11)                                      [32, 384, 4, 4]      [32, 384, 4, 4]      2,281,824            True\n",
              "│    │    └─MBConv (12)                                      [32, 384, 4, 4]      [32, 384, 4, 4]      2,281,824            True\n",
              "│    └─Sequential (7)                                        [32, 384, 4, 4]      [32, 640, 4, 4]      --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 384, 4, 4]      [32, 640, 4, 4]      2,835,296            True\n",
              "│    │    └─MBConv (1)                                       [32, 640, 4, 4]      [32, 640, 4, 4]      6,199,200            True\n",
              "│    │    └─MBConv (2)                                       [32, 640, 4, 4]      [32, 640, 4, 4]      6,199,200            True\n",
              "│    │    └─MBConv (3)                                       [32, 640, 4, 4]      [32, 640, 4, 4]      6,199,200            True\n",
              "│    └─Conv2dNormActivation (8)                              [32, 640, 4, 4]      [32, 2560, 4, 4]     --                   True\n",
              "│    │    └─Conv2d (0)                                       [32, 640, 4, 4]      [32, 2560, 4, 4]     1,638,400            True\n",
              "│    │    └─BatchNorm2d (1)                                  [32, 2560, 4, 4]     [32, 2560, 4, 4]     5,120                True\n",
              "│    │    └─SiLU (2)                                         [32, 2560, 4, 4]     [32, 2560, 4, 4]     --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [32, 2560, 4, 4]     [32, 2560, 1, 1]     --                   --\n",
              "├─Sequential (classifier)                                    [32, 2560]           [32, 1000]           --                   True\n",
              "│    └─Dropout (0)                                           [32, 2560]           [32, 2560]           --                   --\n",
              "│    └─Linear (1)                                            [32, 2560]           [32, 1000]           2,561,000            True\n",
              "============================================================================================================================================\n",
              "Total params: 66,347,960\n",
              "Trainable params: 66,347,960\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 54.34\n",
              "============================================================================================================================================\n",
              "Input size (MB): 6.29\n",
              "Forward/backward pass size (MB): 6709.43\n",
              "Params size (MB): 265.39\n",
              "Estimated Total Size (MB): 6981.12\n",
              "============================================================================================================================================"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get a summary of EfficientNet model\n",
        "summary(model=model,\n",
        "        input_size=(32, 3, size, size),\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klsoI9dTxEYd"
      },
      "source": [
        "Now, we are going to freeze some base layers of the pretrained model and adjust the output layers (Classifier layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zeUtzVqRxbAG"
      },
      "outputs": [],
      "source": [
        "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw-GsB5Qxeim",
        "outputId": "b35625af-b57f-459f-e5f1-01d20ab0707a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adapting model...\n",
            "Num. of classes: 2 \n",
            "Num. of features: 2560\n"
          ]
        }
      ],
      "source": [
        "# Adapt the classifier layers\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "output_shape = 2 # HotDog and NotHotDog\n",
        "num_features = (model.classifier[-1].in_features)\n",
        "\n",
        "print(f\"Adapting model...\")\n",
        "print(f\"Num. of classes: {output_shape} \")\n",
        "print(f\"Num. of features: {num_features}\")\n",
        "\n",
        "# Recreate the classifier layer and seed it to the target device\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=num_features,\n",
        "                    out_features=output_shape,\n",
        "                    bias=True)).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1U-y_pdx4ua",
        "outputId": "cc7942bb-701f-4b2b-b936-1067e31d7cd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "EfficientNet (EfficientNet)                                  [32, 3, 128, 128]    [32, 2]              --                   Partial\n",
              "├─Sequential (features)                                      [32, 3, 128, 128]    [32, 2560, 4, 4]     --                   False\n",
              "│    └─Conv2dNormActivation (0)                              [32, 3, 128, 128]    [32, 64, 64, 64]     --                   False\n",
              "│    │    └─Conv2d (0)                                       [32, 3, 128, 128]    [32, 64, 64, 64]     (1,728)              False\n",
              "│    │    └─BatchNorm2d (1)                                  [32, 64, 64, 64]     [32, 64, 64, 64]     (128)                False\n",
              "│    │    └─SiLU (2)                                         [32, 64, 64, 64]     [32, 64, 64, 64]     --                   --\n",
              "│    └─Sequential (1)                                        [32, 64, 64, 64]     [32, 32, 64, 64]     --                   False\n",
              "│    │    └─MBConv (0)                                       [32, 64, 64, 64]     [32, 32, 64, 64]     (4,944)              False\n",
              "│    │    └─MBConv (1)                                       [32, 32, 64, 64]     [32, 32, 64, 64]     (1,992)              False\n",
              "│    │    └─MBConv (2)                                       [32, 32, 64, 64]     [32, 32, 64, 64]     (1,992)              False\n",
              "│    │    └─MBConv (3)                                       [32, 32, 64, 64]     [32, 32, 64, 64]     (1,992)              False\n",
              "│    └─Sequential (2)                                        [32, 32, 64, 64]     [32, 48, 32, 32]     --                   False\n",
              "│    │    └─MBConv (0)                                       [32, 32, 64, 64]     [32, 48, 32, 32]     (21,224)             False\n",
              "│    │    └─MBConv (1)                                       [32, 48, 32, 32]     [32, 48, 32, 32]     (38,700)             False\n",
              "│    │    └─MBConv (2)                                       [32, 48, 32, 32]     [32, 48, 32, 32]     (38,700)             False\n",
              "│    │    └─MBConv (3)                                       [32, 48, 32, 32]     [32, 48, 32, 32]     (38,700)             False\n",
              "│    │    └─MBConv (4)                                       [32, 48, 32, 32]     [32, 48, 32, 32]     (38,700)             False\n",
              "│    │    └─MBConv (5)                                       [32, 48, 32, 32]     [32, 48, 32, 32]     (38,700)             False\n",
              "│    │    └─MBConv (6)                                       [32, 48, 32, 32]     [32, 48, 32, 32]     (38,700)             False\n",
              "│    └─Sequential (3)                                        [32, 48, 32, 32]     [32, 80, 16, 16]     --                   False\n",
              "│    │    └─MBConv (0)                                       [32, 48, 32, 32]     [32, 80, 16, 16]     (52,588)             False\n",
              "│    │    └─MBConv (1)                                       [32, 80, 16, 16]     [32, 80, 16, 16]     (110,580)            False\n",
              "│    │    └─MBConv (2)                                       [32, 80, 16, 16]     [32, 80, 16, 16]     (110,580)            False\n",
              "│    │    └─MBConv (3)                                       [32, 80, 16, 16]     [32, 80, 16, 16]     (110,580)            False\n",
              "│    │    └─MBConv (4)                                       [32, 80, 16, 16]     [32, 80, 16, 16]     (110,580)            False\n",
              "│    │    └─MBConv (5)                                       [32, 80, 16, 16]     [32, 80, 16, 16]     (110,580)            False\n",
              "│    │    └─MBConv (6)                                       [32, 80, 16, 16]     [32, 80, 16, 16]     (110,580)            False\n",
              "│    └─Sequential (4)                                        [32, 80, 16, 16]     [32, 160, 8, 8]      --                   False\n",
              "│    │    └─MBConv (0)                                       [32, 80, 16, 16]     [32, 160, 8, 8]      (141,460)            False\n",
              "│    │    └─MBConv (1)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      (397,800)            False\n",
              "│    │    └─MBConv (2)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      (397,800)            False\n",
              "│    │    └─MBConv (3)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      (397,800)            False\n",
              "│    │    └─MBConv (4)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      (397,800)            False\n",
              "│    │    └─MBConv (5)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      (397,800)            False\n",
              "│    │    └─MBConv (6)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      (397,800)            False\n",
              "│    │    └─MBConv (7)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      (397,800)            False\n",
              "│    │    └─MBConv (8)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      (397,800)            False\n",
              "│    │    └─MBConv (9)                                       [32, 160, 8, 8]      [32, 160, 8, 8]      (397,800)            False\n",
              "│    └─Sequential (5)                                        [32, 160, 8, 8]      [32, 224, 8, 8]      --                   False\n",
              "│    │    └─MBConv (0)                                       [32, 160, 8, 8]      [32, 224, 8, 8]      (474,728)            False\n",
              "│    │    └─MBConv (1)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      (793,464)            False\n",
              "│    │    └─MBConv (2)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      (793,464)            False\n",
              "│    │    └─MBConv (3)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      (793,464)            False\n",
              "│    │    └─MBConv (4)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      (793,464)            False\n",
              "│    │    └─MBConv (5)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      (793,464)            False\n",
              "│    │    └─MBConv (6)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      (793,464)            False\n",
              "│    │    └─MBConv (7)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      (793,464)            False\n",
              "│    │    └─MBConv (8)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      (793,464)            False\n",
              "│    │    └─MBConv (9)                                       [32, 224, 8, 8]      [32, 224, 8, 8]      (793,464)            False\n",
              "│    └─Sequential (6)                                        [32, 224, 8, 8]      [32, 384, 4, 4]      --                   False\n",
              "│    │    └─MBConv (0)                                       [32, 224, 8, 8]      [32, 384, 4, 4]      (1,008,824)          False\n",
              "│    │    └─MBConv (1)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      (2,281,824)          False\n",
              "│    │    └─MBConv (2)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      (2,281,824)          False\n",
              "│    │    └─MBConv (3)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      (2,281,824)          False\n",
              "│    │    └─MBConv (4)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      (2,281,824)          False\n",
              "│    │    └─MBConv (5)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      (2,281,824)          False\n",
              "│    │    └─MBConv (6)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      (2,281,824)          False\n",
              "│    │    └─MBConv (7)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      (2,281,824)          False\n",
              "│    │    └─MBConv (8)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      (2,281,824)          False\n",
              "│    │    └─MBConv (9)                                       [32, 384, 4, 4]      [32, 384, 4, 4]      (2,281,824)          False\n",
              "│    │    └─MBConv (10)                                      [32, 384, 4, 4]      [32, 384, 4, 4]      (2,281,824)          False\n",
              "│    │    └─MBConv (11)                                      [32, 384, 4, 4]      [32, 384, 4, 4]      (2,281,824)          False\n",
              "│    │    └─MBConv (12)                                      [32, 384, 4, 4]      [32, 384, 4, 4]      (2,281,824)          False\n",
              "│    └─Sequential (7)                                        [32, 384, 4, 4]      [32, 640, 4, 4]      --                   False\n",
              "│    │    └─MBConv (0)                                       [32, 384, 4, 4]      [32, 640, 4, 4]      (2,835,296)          False\n",
              "│    │    └─MBConv (1)                                       [32, 640, 4, 4]      [32, 640, 4, 4]      (6,199,200)          False\n",
              "│    │    └─MBConv (2)                                       [32, 640, 4, 4]      [32, 640, 4, 4]      (6,199,200)          False\n",
              "│    │    └─MBConv (3)                                       [32, 640, 4, 4]      [32, 640, 4, 4]      (6,199,200)          False\n",
              "│    └─Conv2dNormActivation (8)                              [32, 640, 4, 4]      [32, 2560, 4, 4]     --                   False\n",
              "│    │    └─Conv2d (0)                                       [32, 640, 4, 4]      [32, 2560, 4, 4]     (1,638,400)          False\n",
              "│    │    └─BatchNorm2d (1)                                  [32, 2560, 4, 4]     [32, 2560, 4, 4]     (5,120)              False\n",
              "│    │    └─SiLU (2)                                         [32, 2560, 4, 4]     [32, 2560, 4, 4]     --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [32, 2560, 4, 4]     [32, 2560, 1, 1]     --                   --\n",
              "├─Sequential (classifier)                                    [32, 2560]           [32, 2]              --                   True\n",
              "│    └─Dropout (0)                                           [32, 2560]           [32, 2560]           --                   --\n",
              "│    └─Linear (1)                                            [32, 2560]           [32, 2]              5,122                True\n",
              "============================================================================================================================================\n",
              "Total params: 63,792,082\n",
              "Trainable params: 5,122\n",
              "Non-trainable params: 63,786,960\n",
              "Total mult-adds (Units.GIGABYTES): 54.26\n",
              "============================================================================================================================================\n",
              "Input size (MB): 6.29\n",
              "Forward/backward pass size (MB): 6709.18\n",
              "Params size (MB): 255.17\n",
              "Estimated Total Size (MB): 6970.64\n",
              "============================================================================================================================================"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print model summary of the adapted model\n",
        "# # Do a summary *after* freezing the features and changing the output classifier layer (uncomment for actual output)\n",
        "summary(model,\n",
        "        input_size=(32, 3, size, size),\n",
        "        verbose=0,\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lR7dY0bzN-t"
      },
      "source": [
        "### Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YUtyX2qK0WlB"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device) -> Tuple[float, float]:\n",
        "    \"\"\"Trains a PyTorch model for a single epoch.\n",
        "\n",
        "    Turns a target PyTorch model to training mode and then\n",
        "    runs through all of the required training steps (forward\n",
        "    pass, loss calculation, optimizer step).\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be trained.\n",
        "    dataloader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy). For example:\n",
        "\n",
        "    (0.1112, 0.8743)\n",
        "    \"\"\"\n",
        "    # Put model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # Setup train loss and train accuracy values\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Loop through data loader data batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Send data to target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate  and accumulate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate and accumulate accuracy metric across all batches\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "    \"\"\"Tests a PyTorch model for a single epoch.\n",
        "\n",
        "    Turns a target PyTorch model to \"eval\" mode and then performs\n",
        "    a forward pass on a testing dataset.\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be tested.\n",
        "    dataloader: A DataLoader instance for the model to be tested on.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A tuple of testing loss and testing accuracy metrics.\n",
        "    In the form (test_loss, test_accuracy). For example:\n",
        "\n",
        "    (0.0223, 0.8985)\n",
        "    \"\"\"\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Setup test loss and test accuracy values\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate and accumulate loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Calculate and accumulate accuracy\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "\n",
        "def train_model(model: nn.Module,\n",
        "                train_dataloader: DataLoader,\n",
        "                test_dataloader: DataLoader,\n",
        "                optimizer: torch.optim.Optimizer,\n",
        "                loss_fn: nn.Module,\n",
        "                epochs: int,\n",
        "                device: torch.device)->Dict[str, List]:\n",
        "                    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "upx9K4bLzTTu"
      },
      "outputs": [],
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "db387279b4e14319b16b649483a055dd",
            "65b1348e2ac14316ae7d556e00e18db1",
            "5c8ced3d17b14495b996a403a2cae27a",
            "65d67348b80841d59e9f8c74a36b4ea1",
            "cc62a905947448cfa85aca800ead3a43",
            "96b07ce35c624173979d4a373af9f989",
            "359e8eb5f5424448a244c5472fba42d5",
            "0d791bc545b3475ca8f4887e925f926a",
            "da9a347d291a4da38a163a48e7575b4d",
            "9b5b2b235d174448a3ab40931280cdef",
            "7215f8baaf5e4fb9b03e1e5a9c2bdf9a"
          ]
        },
        "id": "6jFOZ9x1yCQM",
        "outputId": "b981f3ab-e340-471b-962d-d6f1dc9e1e20"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db387279b4e14319b16b649483a055dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.5632 | train_acc: 0.7421 | test_loss: 0.5236 | test_acc: 0.7573\n",
            "Epoch: 2 | train_loss: 0.4420 | train_acc: 0.8158 | test_loss: 0.4837 | test_acc: 0.7859\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3754450672.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Setup training and save the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m results = train_model(model=model,\n\u001b[0m\u001b[1;32m     12\u001b[0m                        \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                        \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2241052551.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device)\u001b[0m\n\u001b[1;32m    133\u001b[0m                                           \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                                           device=device)\n\u001b[0;32m--> 135\u001b[0;31m         test_loss, test_acc = test_step(model=model,\n\u001b[0m\u001b[1;32m    136\u001b[0m           \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m           \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2241052551.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(model, dataloader, loss_fn, device)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# 1. Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mtest_pred_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;31m# 2. Calculate and accumulate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res_connect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "# Set the random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "results = train_model(model=model,\n",
        "                       train_dataloader=train_loader,\n",
        "                       test_dataloader=test_loader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=5,\n",
        "                       device=device)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyzxtP5H2hMD"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQtFnCJc2jD5"
      },
      "outputs": [],
      "source": [
        "# Get the plotWeight the 2D activations by the average gradient_loss_curves() function from helper_functions.py, download the file if we don't have it\n",
        "try:\n",
        "    from helper_functions import plot_loss_curves\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find helper_functions.py, downloading...\")\n",
        "    with open(\"helper_functions.py\", \"wb\") as f:\n",
        "        import requests\n",
        "        request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "        f.write(request.content)\n",
        "    from helper_functions import plot_loss_curves\n",
        "\n",
        "# Plot the loss curves of our model\n",
        "plot_loss_curves(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbSwrjpY23lK"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NulyJRe_25zk"
      },
      "outputs": [],
      "source": [
        "# 1. Take in a trained model, class names, image path, image size, a transform and target device\n",
        "def pred_and_plot_image(model: torch.nn.Module,\n",
        "                        image_path: List[str],\n",
        "                        class_names: List[str],\n",
        "                        image_size: Tuple[int, int] = (128, 128),\n",
        "                        transform: transforms = None,\n",
        "                        device: torch.device=device):\n",
        "\n",
        "    \"\"\"\n",
        "    Predict and plot images in a 4x3 grid showing predicted class and probability.\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure model is on correct device\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Create transform if not provided\n",
        "    if transform is not None:\n",
        "        image_transform = transform\n",
        "    else:\n",
        "        image_transform = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean,\n",
        "                                 std=std),\n",
        "        ])\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Loop through up to 12 images\n",
        "    for i, image_path in enumerate(image_path[:len(image_path)]):\n",
        "        img = Image.open(image_path).convert(\"RGB\")\n",
        "        transformed_image = image_transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            pred = model(transformed_image)\n",
        "\n",
        "        pred_probs = torch.softmax(pred, dim=1)\n",
        "        pred_label = torch.argmax(pred_probs, dim=1).item()\n",
        "        pred_prob = pred_probs[0, pred_label].item()\n",
        "\n",
        "        # Plot image\n",
        "        axes[i].imshow(img.resize(image_size))\n",
        "        axes[i].set_title(f\"{class_names[pred_label]} ({pred_prob*100:.1f}%)\", fontsize=10)\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    # Turn off any empty subplots\n",
        "    for j in range(len(image_path), 12):\n",
        "        axes[j].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agI8zd-Z3NVo"
      },
      "source": [
        "**Saliency map**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F_QiQyPGoQl"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def add_gaussian_noise(tensor: torch.Tensor, std: float = 0.1) -> torch.Tensor:\n",
        "    \"\"\"Adds Gaussian noise to a tensor image.\"\"\"\n",
        "    noise = torch.randn_like(tensor) * std\n",
        "    return torch.clamp(tensor + noise, 0.0, 1.0)\n",
        "\n",
        "def pred_sal(model: torch.nn.Module,\n",
        "             image_path: str,\n",
        "             class_names: List[str],\n",
        "             image_size: Tuple[int, int] = (128, 128),\n",
        "             transform: transforms.Compose = None,\n",
        "             device: torch.device = torch.device(\"cpu\"),\n",
        "             n_samples: int = 10,\n",
        "             noise_std: float = 0.25):\n",
        "    \"\"\"\n",
        "    Predicts on a single image and visualizes the original image\n",
        "    with its SmoothGrad saliency map.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Load image ---\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # --- Define transform if not provided ---\n",
        "    if transform is None:\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    # --- Apply transform and prepare tensor ---\n",
        "    X = transform(img).unsqueeze(0).to(device)\n",
        "    X.requires_grad_()\n",
        "\n",
        "    # --- Model prediction ---\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    scores = model(X)\n",
        "    probs = torch.softmax(scores, dim=1)\n",
        "    pred_label = torch.argmax(probs, dim=1)\n",
        "\n",
        "    # --- SmoothGrad: accumulate gradients over noisy samples ---\n",
        "    saliency_total = torch.zeros_like(X)\n",
        "    for _ in range(n_samples):\n",
        "        noisy_X = X + torch.randn_like(X) * noise_std\n",
        "        noisy_X.requires_grad_()\n",
        "        noisy_X.retain_grad()\n",
        "        model.zero_grad()\n",
        "        out = model(noisy_X)\n",
        "        score_max = out[0, pred_label[0]]\n",
        "        score_max.backward()\n",
        "        saliency_total += noisy_X.grad.abs()\n",
        "\n",
        "    saliency = saliency_total / n_samples\n",
        "    saliency = saliency.max(dim=1)[0].detach().cpu()  # collapse channels\n",
        "\n",
        "    # --- Normalize for plotting ---\n",
        "    saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min() + 1e-10)\n",
        "\n",
        "    # --- Plot original image and saliency map side by side ---\n",
        "    plt.figure(figsize=(10,5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Pred: {class_names[pred_label[0]]}\\nProb: {probs.max():.3f}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(saliency[0], cmap='hot')\n",
        "    plt.title(\"SmoothGrad Saliency\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k3-RKg3D3DK8"
      },
      "outputs": [],
      "source": [
        "# Get a random list of image paths from test set\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "num_images_to_plot = 10\n",
        "test_image_path_list = list(Path('/content/hotdog_nothotdog/test').glob(\"*/*.jpg\")) # get list all image paths from test data\n",
        "test_image_path_sample = random.sample(population=test_image_path_list, # go through all of the test image paths\n",
        "                                       k=num_images_to_plot) # randomly select 'k' image paths to pred and plot\n",
        "class_names = ['HotDog', 'NotHogDog']\n",
        "# Make predictions on and plot the images\n",
        "for image_path in test_image_path_sample:\n",
        "    pred_sal(model=model,\n",
        "              image_path=image_path,\n",
        "                        class_names=class_names,\n",
        "                        # transform=weights.transforms(), # optionally pass in a specified transform from our pretrained model weights\n",
        "                        image_size=(128, 128))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FAMrnan9eVl"
      },
      "outputs": [],
      "source": [
        "def saliency_map(model: torch.nn.Module,\n",
        "                 dataloader: torch.utils.data.DataLoader,\n",
        "                 device: torch.device = torch.device(\"cpu\")) -> None:\n",
        "    \"\"\"Visualizes a saliency map for the first image in a DataLoader batch.\"\"\"\n",
        "\n",
        "    model.eval()  # Make sure model is in eval mode\n",
        "\n",
        "    # Get first batch\n",
        "    X, y = next(iter(dataloader))\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    X.requires_grad_()  # Track gradients w.r.t input\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X)\n",
        "    predicted_class = outputs.argmax(dim=1)\n",
        "\n",
        "    # Compute loss for the predicted class of the first image\n",
        "    loss = outputs[0, predicted_class[0]]  # Only first image\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Saliency = max absolute gradient across channels\n",
        "    saliency = X.grad.data.abs().max(dim=1)[0].cpu()\n",
        "\n",
        "    # Plot the first image's saliency\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.imshow(saliency[0], cmap=plt.cm.hot)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Predicted class: {predicted_class[0].item()}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "saliency_map(model=model, dataloader=train_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwEBof0xCIKM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def add_gaussian_noise(tensor: torch.Tensor, std: float = 0.1) -> torch.Tensor:\n",
        "    \"\"\"Adds Gaussian noise to a tensor image.\"\"\"\n",
        "    noise = torch.randn_like(tensor) * std\n",
        "    noisy_tensor = tensor + noise\n",
        "    return torch.clamp(noisy_tensor, 0.0, 1.0)\n",
        "\n",
        "def pred_sal(model: torch.nn.Module,\n",
        "             image_path: str,\n",
        "             class_names: List[str],\n",
        "             image_size: Tuple[int, int] = (128, 128),\n",
        "             transform: transforms.Compose = None,\n",
        "             device: torch.device = torch.device(\"cpu\"),\n",
        "             n_samples: int = 10,\n",
        "             noise_std: float = 0.1):\n",
        "    \"\"\"\n",
        "    Predicts on a single image and visualizes the original image\n",
        "    with its SmoothGrad saliency map side by side.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Load and transform image ---\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    if transform is None:\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "    X = transform(img).unsqueeze(0).to(device)\n",
        "    X.requires_grad_()\n",
        "\n",
        "    # --- Prediction ---\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    outputs = model(X)\n",
        "    probs = torch.softmax(outputs, dim=1)\n",
        "    pred_label = torch.argmax(probs, dim=1)\n",
        "\n",
        "    # --- Compute SmoothGrad saliency ---\n",
        "    saliency_total = torch.zeros_like(X)\n",
        "    for _ in range(n_samples):\n",
        "        noisy_X = add_gaussian_noise(X, std=noise_std)\n",
        "        noisy_X.requires_grad_()\n",
        "        model.zero_grad()\n",
        "        out = model(noisy_X)\n",
        "        loss = out[0, pred_label[0]]\n",
        "        loss.backward()\n",
        "        saliency_total += noisy_X.grad.data.abs()\n",
        "\n",
        "    saliency = saliency_total / n_samples\n",
        "    saliency = saliency.max(dim=1)[0].cpu()  # collapse channels\n",
        "\n",
        "    # --- Plot original image and SmoothGrad saliency map side by side ---\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Original image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Pred: {class_names[pred_label[0]]}\\nProb: {probs.max():.3f}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # SmoothGrad saliency map\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(saliency[0], cmap=plt.cm.hot)\n",
        "    plt.title(\"SmoothGrad Saliency\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5JsQiS6CSJH"
      },
      "outputs": [],
      "source": [
        "# Get a random list of image paths from test set\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "num_images_to_plot = 12\n",
        "test_image_path_list = list(Path('/content/hotdog_nothotdog/test').glob(\"*/*.jpg\")) # get list all image paths from test data\n",
        "test_image_path_sample = random.sample(population=test_image_path_list, # go through all of the test image paths\n",
        "                                       k=num_images_to_plot) # randomly select 'k' image paths to pred and plot\n",
        "class_names = ['Hot_Dog', 'Not_Hot_Dog']\n",
        "# Make predictions on and plot the images\n",
        "for image_path in test_image_path_sample:\n",
        "    pred_and_plot_image(model=model,\n",
        "                        image_path=image_path,\n",
        "                        class_names=class_names,\n",
        "                        image_size=(128, 128))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d791bc545b3475ca8f4887e925f926a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "359e8eb5f5424448a244c5472fba42d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c8ced3d17b14495b996a403a2cae27a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d791bc545b3475ca8f4887e925f926a",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da9a347d291a4da38a163a48e7575b4d",
            "value": 2
          }
        },
        "65b1348e2ac14316ae7d556e00e18db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96b07ce35c624173979d4a373af9f989",
            "placeholder": "​",
            "style": "IPY_MODEL_359e8eb5f5424448a244c5472fba42d5",
            "value": " 40%"
          }
        },
        "65d67348b80841d59e9f8c74a36b4ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b5b2b235d174448a3ab40931280cdef",
            "placeholder": "​",
            "style": "IPY_MODEL_7215f8baaf5e4fb9b03e1e5a9c2bdf9a",
            "value": " 2/5 [39:57&lt;41:18, 826.05s/it]"
          }
        },
        "7215f8baaf5e4fb9b03e1e5a9c2bdf9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96b07ce35c624173979d4a373af9f989": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b5b2b235d174448a3ab40931280cdef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc62a905947448cfa85aca800ead3a43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da9a347d291a4da38a163a48e7575b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db387279b4e14319b16b649483a055dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65b1348e2ac14316ae7d556e00e18db1",
              "IPY_MODEL_5c8ced3d17b14495b996a403a2cae27a",
              "IPY_MODEL_65d67348b80841d59e9f8c74a36b4ea1"
            ],
            "layout": "IPY_MODEL_cc62a905947448cfa85aca800ead3a43"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
